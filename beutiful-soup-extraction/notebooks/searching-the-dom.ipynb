{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find for a spefic node, or group of nodes inside the DOM is a daunting task. Modern websites could have thousands of nodes, organised somehow to suit their needs. \n",
    "Trying to find a specific node, or group of nodes, is a task that could take hours, if not days. \n",
    "This is where the power of BeautifulSoup comes in.BeautifulSoup allows us to `search` the DOM, and find the nodes we are looking for, in a matter of seconds. \n",
    "\n",
    "In this notebook, we will explore the different ways we can search the DOM, and find the nodes we are looking for.\n",
    "\n",
    "For this example we will use the sample page [simple-page.html](../data/simple-page.html), stored in the `data` folder. \n",
    "\n",
    "The page represents mock of  a search result, where two employees are listed and their relevant information are displayed in a card."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> Note: In a browser you can right click in the page, and select View Page Source to view the Actual html-string, or `Inspect` to see the DOM of the page."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ways to search the DOM\n",
    "##### Using the `find` or the `find_all` method\n",
    "\n",
    "the .find() and .find_all() methods are the most common ways to search the DOM. The biggest difference between the two is that the .find() method will return the first match, while the .find_all() method will return all the matches.\n",
    "\n",
    "The formal definition of the .find() and .find_all() methods is as follows:\n",
    "\n",
    "    find(name, attrs, recursive, string, **kwargs)\n",
    "    find_all(name, attrs, recursive, string, limit, **kwargs)\n",
    "    \n",
    " - `name` - the name of the tag to search for\n",
    "    - if the name is not provided, bs4 will search for all `name` tags. i.e title, span, div, etc.\n",
    " - `recursive` - whether or not to search inside children of the current node\n",
    "    - if `recursive` is set to `False`, bs4 will only consider the current's node direct children. \n",
    " - `string` - the text to search for\n",
    "    - if `string` is provided, bs4 will only return nodes that pass the filter. The filter could be a string, a regular expression, or a function that returns true or false.\n",
    " - ** `kwargs` - any other arguments that can be passed to the `find` or `find_all` methods, will be used to filter nodes based on their `attributes`\n",
    "    - if we want to search for tags that have id = 'id-123' then we can pass `id='id-123'` as a keyword argument. As with the string, the value don't need to be a specific string, it can be a regular expression, or a function that returns true or false.\n",
    " - `attrs` - a dictionary of attributes to search for\n",
    "    - some attributes like data-foo can't be expressed as as kwargs. in cases like this, we can use the `attrs` argument to pass a dictionary of attributes to search for. i.e `attrs={'data-foo': 'bar'}` \n",
    "\n",
    "\n",
    "#### CSS Selectors\n",
    "CSS Selectors are string patterns that can be used to express nodes in the DOM. They are somewhat similar to XPath but they are much easier to use, and more powerful.  \n",
    "> Note: A full list of the Css selects are available [here](https://www.w3schools.com/cssref/css_selectors.asp).\n",
    "\n",
    "BeautifulSoup uses the SoupSieve package to run a CSS selector against a parsed document and return all the matching elements. If it's not already installed, you can install it using the following command:\n",
    "\n",
    "~~~bash\n",
    "    pip install soupsieve\n",
    "~~~\n",
    "> Note: That if that \n",
    "\n",
    "##### Using the `select` and select_one` methods\n",
    "As the find and find_all methods, the select and select_one  will find all the matches, while the select_one method will return just the first match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "html_doc = Path(\"../data/simple-page.html\").read_text()\n",
    "html_doc = \"\".join(line.strip() for line in html_doc.split(\"\\n\"))\n",
    "soup = BeautifulSoup(html_doc, \"html.parser\")\n",
    "soup \n",
    "# <html>...</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the ID attribute.\n",
    "Each tag _could_ contain an `id` attribute. This attribute is _unique_ (but not enforsable) for within the HTML document and can be used to find a specific tag.  \n",
    "_Un_ fortunally as the HTML is designed to be fault toleurant, browsers will happy render the DOM without complainin using the '#' character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "html_doc = Path(\"../data/simple-page.html\").read_text()\n",
    "html_doc = \"\".join(line.strip() for line in html_doc.split(\"\\n\"))\n",
    "soup = BeautifulSoup(html_doc, \"html\")\n",
    "person = soup.select_one(\"#name-QTV9J\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"card-header solid-orange\" id=\"name-QTV9J\"><h>Person:</h><span>Jane Doe</span></div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person\n",
    "# <div class=\"card-header solid-orange\" id=\"name-QTV9J\"><h>Person:</h><span>Jane Doe</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'banner', 'class': ['solid-green', 'result-banner']}\n",
      "{'id': 'result-item-1', 'class': ['result-item', 'solid-green']}\n",
      "{'id': 'result-item-2', 'class': ['result-item', 'solid-green']}\n"
     ]
    }
   ],
   "source": [
    "for c in p.children:\n",
    "    print(c.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ul {'class': ['solid-green', 'data']}\n",
      "\t Occupation: Programmer\n",
      "\t Room: 1234-A\n",
      "\t Building: AAAAA\n",
      "ul {'class': ['solid-green', 'data']}\n",
      "\t Occupation: System Architect\n",
      "\t Room: 1234-C\n",
      "\t Building: BBBBB\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "html_doc = Path(\"../data/simple-page.html\").read_text()\n",
    "html_doc = \"\".join(line.strip() for line in html_doc.split(\"\\n\"))\n",
    "soup = BeautifulSoup(html_doc, \"html\")\n",
    "\n",
    "for children in soup.select('ul.data'):\n",
    "    print(children.name, children.attrs, )\n",
    "    for c in children.children:\n",
    "        print('\\t',c.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beutiful-soup-extraction-Ku8d3yTG-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "595c9d301ad35a04f969b524eb2e2ca3caf3acfd4496e718f40bf36448d2d26f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
