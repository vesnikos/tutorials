{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script bellow will scrape data from https://www.billboard.com/charts/billboard-200/ a website that contains the top 200 songs of the week. The data will be stored in a json file.\n",
    "\n",
    "to run the script, an aditional library is needed, pydantic. To install it, run the following command in your terminal:\n",
    "~~~bash\n",
    "$ pip install pydantic\n",
    "~~~\n",
    "\n",
    "> Note: Pydantic is a validation library, focused on loading the data into a model that makes sure that is stronlgly typed. I absolutely recommend it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "\n",
    "import bs4\n",
    "from pydantic import BaseModel, HttpUrl, ValidationError\n",
    "from requests import get\n",
    "\n",
    "TARGET_URL = 'https://www.billboard.com/charts/billboard-200/'\n",
    "\n",
    "\n",
    "class BillBoardItem(BaseModel):\n",
    "    # scraped_timestamp is of type datetime. if not suplied, it will be set by default to datetime.now()\n",
    "    scraped_timestamp: datetime = datetime.now()\n",
    "    this_week_rank: int\n",
    "    # url is of type HttpUrl, which is a str with a valid URL.\n",
    "    url_photo: HttpUrl\n",
    "    artist: str\n",
    "    track_name: str\n",
    "    last_week_rank: str\n",
    "    peak_position: int\n",
    "    weeks_on_chart: str\n",
    "\n",
    "\n",
    "def get_parser(text) -> bs4.BeautifulSoup:\n",
    "    parser = bs4.BeautifulSoup(\n",
    "        markup=text,\n",
    "        features='html.parser'\n",
    "    )\n",
    "    return parser\n",
    "\n",
    "\n",
    "def parse_result(container_row: bs4.Tag) -> BillBoardItem:\n",
    "    last_week_rank,peak_position, weeks_on_chart =[t.text.strip() for t in container_row.select('li.o-chart-results-list__item > span.c-label')[-3:]]\n",
    "    this_week_rank, last_week_compare, track_name, artist_name = [t.text.strip() for t in container_row.select('li.o-chart-results-list__item span.c-label')[:4]]\n",
    "    image_urls = [img.attrs['data-lazy-src'] for img in container_row.select('img.c-lazy-image__img')]\n",
    "    track_name = container_row.select_one('#title-of-a-story').text.strip()\n",
    "    label= container_row.select_one('h3.c-title ~ p.c-tagline').text.strip\n",
    "    data = {\n",
    "        'this_week_rank': this_week_rank,\n",
    "        'url_photo': image_urls[-1],\n",
    "        'label': label,\n",
    "        'track_name': track_name,\n",
    "        'artist': artist_name,\n",
    "        'last_week_rank': last_week_rank,\n",
    "        'peak_position': peak_position,\n",
    "        'weeks_on_chart': weeks_on_chart\n",
    "        }\n",
    "    try:\n",
    "        return BillBoardItem(**data)\n",
    "    except ValidationError as e:\n",
    "        print(data)\n",
    "        raise e\n",
    "def parse_website(text: str) -> List[BillBoardItem]:\n",
    "    parser = get_parser(text)\n",
    "    items: List[BillBoardItem] = []\n",
    "    for idx, tag in enumerate(parser.find_all('div', class_={'o-chart-results-list-row-container'})):\n",
    "        items.append(parse_result(container_row=tag))\n",
    "    return items\n",
    "\n",
    "\n",
    "def main(**kwargs):\n",
    "    output = kwargs.get('output', sys.stdout)\n",
    "\n",
    "    r = get(url=TARGET_URL)\n",
    "    r.raise_for_status()\n",
    "    text = r.text\n",
    "    elements = parse_website(text)\n",
    "    for e in elements:\n",
    "        print(e.json(), file=output)\n",
    "\n",
    "\n",
    "with open('billboard200.jsonl', 'w') as f:\n",
    "    main(output=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises:\n",
    "##### Grouping Key: \n",
    "Every week the entries are moving (or added/removed) according to their popularity.\n",
    "Create key based on the data to track their movement over the weeks.\n",
    " - Modify the BillBoardItem to include an id field, that auto-populates based on the data\n",
    "     - and read about validators (https://docs.pydantic.dev/usage/validators/) on how to autopopulate it\n",
    "\n",
    "##### Add awards to the data:\n",
    "- Modify the BillBoardItem to include an awards field, that auto-populates based on the data\n",
    "- tip: start with a sample row, and then try to extract the awards from it. \n",
    "    - Use the following code get started.\n",
    "    - get a list of all the rows, and then use the website to determine which row has awards on it\n",
    "    - then bit by bit try to extract the awards fields\n",
    "    - after you're succefull, modify the code to add the awards to the BillBoardItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "\n",
    "import bs4\n",
    "from pydantic import BaseModel, HttpUrl, ValidationError\n",
    "from requests import get\n",
    "\n",
    "TARGET_URL = 'https://www.billboard.com/charts/billboard-200/'\n",
    "def get_parser(text) -> bs4.BeautifulSoup:\n",
    "    parser = bs4.BeautifulSoup(\n",
    "        markup=text,\n",
    "        features='html.parser'\n",
    "    )\n",
    "    return parser\n",
    "r = get(url=TARGET_URL)\n",
    "r.raise_for_status()\n",
    "text = r.text\n",
    "parser = get_parser(text)\n",
    "rows = parser.find_all('div', class_={'o-chart-results-list-row-container'})\n",
    "# which row has awards so you can work with it? chekc the site\n",
    "row = rows[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beutiful-soup-extraction-Ku8d3yTG-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "595c9d301ad35a04f969b524eb2e2ca3caf3acfd4496e718f40bf36448d2d26f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
